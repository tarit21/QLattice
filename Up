import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import httpx
from langchain_openai import ChatOpenAI

# ----------------------
# CONFIG
# ----------------------
BASE_URL = "https://genailab.tcs.in/"
MODEL = "azure_ai/genailab-maas-DeepSeek-V3-0324"
API_KEY = "sk-xxxxx"   # <-- replace with your hackathon key

# ----------------------
# DATA LOADING
# ----------------------
@st.cache_data
def load_data():
    excel_file = "manufacturing_data.xlsx"
    suppliers = pd.read_excel(excel_file, sheet_name="Suppliers")
    inventory = pd.read_excel(excel_file, sheet_name="Inventory")
    usage = pd.read_excel(excel_file, sheet_name="Usage")
    schedule = pd.read_excel(excel_file, sheet_name="Schedule")
    bom = pd.read_excel(excel_file, sheet_name="BOM")
    purchase_orders = pd.read_excel(excel_file, sheet_name="Purchase_Orders")
    return suppliers, inventory, usage, schedule, bom, purchase_orders

suppliers, inventory, usage, schedule, bom, purchase_orders = load_data()

# ----------------------
# LLM CLIENT SETUP
# ----------------------
client = httpx.Client()
llm = ChatOpenAI(
    base_url=BASE_URL,
    model=MODEL,
    api_key=API_KEY,
    http_client=client
)

def ask_llm(query):
    messages = [
        {"role": "system", "content": "You are a manufacturing supply chain assistant."},
        {"role": "user", "content": query}
    ]
    try:
        response = llm.invoke(messages)
        return response.content
    except Exception as e:
        return f"Error: {e}"

# ----------------------
# STREAMLIT UI
# ----------------------
st.set_page_config(page_title="Manufacturing Analytics + LLM", layout="wide")
st.title("🏭 Manufacturing Data Analyzer with LLM")

# Tabs
main_tabs = st.tabs(["📦 Inventory", "📈 Demand", "📑 Purchase Orders", "🤖 Ask LLM"])

# ----------------------
# INVENTORY TAB
# ----------------------
with main_tabs[0]:
    st.subheader("Inventory Overview")
    st.dataframe(inventory.head(20))

    st.write("### Stock Levels vs Reorder Point")
    fig, ax = plt.subplots(figsize=(8, 4))
    inventory.plot(x="part_id", y=["on_hand", "reorder_point"], kind="bar", ax=ax)
    st.pyplot(fig)

# ----------------------
# DEMAND TAB
# ----------------------
with main_tabs[1]:
    st.subheader("Demand Trends (sample 10 parts)")
    sample_parts = usage["part_id"].unique()[:10]
    usage_sample = usage[usage["part_id"].isin(sample_parts)]
    demand_summary = usage_sample.groupby(["date", "part_id"]).demand_qty.sum().reset_index()

    fig, ax = plt.subplots(figsize=(10, 5))
    for pid in sample_parts:
        dfp = demand_summary[demand_summary.part_id == pid]
        ax.plot(dfp.date, dfp.demand_qty, label=pid)
    ax.legend()
    st.pyplot(fig)

# ----------------------
# PURCHASE ORDERS TAB
# ----------------------
with main_tabs[2]:
    st.subheader("Purchase Order Status")
    st.dataframe(purchase_orders.head(20))

    po_summary = purchase_orders.groupby("status").size()
    fig, ax = plt.subplots()
    po_summary.plot(kind="pie", autopct="%1.1f%%", ax=ax)
    ax.set_ylabel("")
    st.pyplot(fig)

# ----------------------
# LLM Q&A TAB
# ----------------------
with main_tabs[3]:
    st.subheader("Chat with Supply Chain Assistant")

    # Quick Ask buttons
    quick_qs = [
        "Which parts are at highest risk of stockout?",
        "Suggest suppliers with lowest lead time.",
        "What is the overall demand trend for Engine parts?",
        "Give insights on delayed purchase orders."
    ]

    cols = st.columns(len(quick_qs))
    for i, q in enumerate(quick_qs):
        if cols[i].button(q):
            st.session_state["chat_query"] = q

    query = st.text_area("Enter your question:", value=st.session_state.get("chat_query", ""))
    if st.button("Ask LLM"):
        with st.spinner("Thinking..."):
            answer = ask_llm(query)
            st.success(answer)

            with st.expander("🔍 Debug Info: Prompt & Response"):
                st.write("**Prompt:**", query)
                st.write("**Response:**", answer)
