import streamlit as st
import pandas as pd
from langchain_openai import ChatOpenAI
import httpx

# --------------------------
# CONFIGURATION
# --------------------------
EXCEL_FILE = "manufacturing_data.xlsx"

BASE_URL = "https://genailab.tcs.in/"
MODEL = "azure_ai/genailab-maas-DeepSeek-V3-0324"
DEEPSEEK_API_KEY = "sk-xxx"   # Replace with your hackathon key

# --------------------------
# LOAD DATA
# --------------------------
@st.cache_data
def load_data(file):
    xls = pd.ExcelFile(file)
    data = {sheet: pd.read_excel(xls, sheet) for sheet in xls.sheet_names}
    return data

# --------------------------
# LLM SETUP (LangChain)
# --------------------------
client = httpx.Client(verify=False)  # Ignore SSL verify
llm = ChatOpenAI(
    base_url=BASE_URL,
    model=MODEL,
    api_key=DEEPSEEK_API_KEY,
    http_client=client
)

def ask_llm(question, context=""):
    messages = [
        {"role": "system", "content": "You are an assistant that answers ONLY using the provided manufacturing data."},
        {"role": "user", "content": f"Data:\n{context}"},
        {"role": "user", "content": f"Question: {question}"}
    ]
    response = llm.invoke(messages)
    return response.content

# --------------------------
# STREAMLIT UI
# --------------------------
st.set_page_config(page_title="Manufacturing Inventory Agent", layout="wide")
st.title("üè≠ Manufacturing Inventory Query & Restock Suggestion Agent")

# Load data
try:
    data = load_data(EXCEL_FILE)
    st.sidebar.success("‚úÖ Data loaded successfully")
except Exception as e:
    st.sidebar.error(f"‚ùå Error loading data: {e}")
    st.stop()

# Sidebar navigation
st.sidebar.header("Navigation")
page = st.sidebar.radio("Go to:", ["Inventory Dashboard", "Ask LLM"])

# --------------------------
# INVENTORY DASHBOARD
# --------------------------
if page == "Inventory Dashboard":
    st.header("üìä Inventory Dashboard")

    if "Inventory" in data:
        st.subheader("Current Inventory")
        st.dataframe(data["Inventory"].head(20))

        # Low stock = on_hand < reorder_point
        low_stock = data["Inventory"][data["Inventory"]["on_hand"] < data["Inventory"]["reorder_point"]]
        if not low_stock.empty:
            st.warning("‚ö†Ô∏è Low Stock Items:")
            st.dataframe(low_stock)

    if "Usage" in data:
        st.subheader("Historical Usage Trends")
        usage_summary = data["Usage"].groupby("part_id")["demand_qty"].sum().reset_index()
        st.bar_chart(usage_summary.set_index("part_id"))

    if "PurchaseOrders" in data:
        st.subheader("Recent Purchase Orders")
        st.dataframe(data["PurchaseOrders"].tail(10))

# --------------------------
# LLM Q&A SECTION
# --------------------------
elif page == "Ask LLM":
    st.header("üîÆ Ask the LLM about Manufacturing Data")

    user_q = st.text_area("Type your question:",
                          placeholder="e.g., Which parts are at risk of stockout next week?")

    if st.button("Ask LLM"):
        if not DEEPSEEK_API_KEY or DEEPSEEK_API_KEY.startswith("sk-xxx"):
            st.error("‚ö†Ô∏è Please set a valid DEEPSEEK_API_KEY in code.")
        else:
            # Provide first 50 rows of inventory as context
            context = data["Inventory"].head(50).to_json(orient="records")
            answer = ask_llm(user_q, context=context)
            st.success(answer)

    st.subheader("Quick Ask")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("Which items need restocking soon?"):
            low_stock = data["Inventory"][data["Inventory"]["on_hand"] < data["Inventory"]["reorder_point"]]
            context = low_stock.to_json(orient="records") if not low_stock.empty else "No low stock"
            answer = ask_llm("Which items need restocking soon?", context)
            st.info(answer)

    with col2:
        if st.button("Suggest suppliers for critical parts"):
            if "PurchaseOrders" in data:
                context = data["PurchaseOrders"].tail(20).to_json(orient="records")
            else:
                context = "No supplier data available"
            answer = ask_llm("Suggest suppliers for critical parts", context)
            st.info(answer)
